*************************************************************************
* File : README.txt 							*
* Developers : Amar Lalwani 						*
* Raghav Bali 								*
* Date : May 14 2013 							*
* Author : Raghav Bali 							*
* Version : 1.1								*
*************************************************************************

The Boolean Retrieval System(TBRS) has gone through a minor update but a defining one.
The project though initially developed for showcasing the Retrieval of documents based upon Boolean Queries was made in modular fashion
so as to support extensions for future works. This flexibility allowed us to utilize this project for developing a Clustering Project,
more specifically a project to showcase Hierarchical Clustering.

TBRS required a few minor additions to make it a suitable preprocessor of corpus for the clustering project. The updates include :

-Postings List : 	The previous version only supported in-memory postings list which was a sort of shortcoming incase the lists
			were to be used by other projects/applications. To overcome this shortcoming a couple of methods were added
			to postingslist.c to serialize the indexing of the corpus documents.

src/postingslist.c :
	-Methods added :	+int persistent_postingslist(char *fileinput,char *originalfile) 
					This method is basically similar to add_document_to_postingslist() with a couple of changes.
					This method keeps the original file names for reference rather than outputfile names (comes handy)
					It also fine tunes the addition of document content to postings list by separating the 
					initialization steps completely.
				
				+void serialize_postings_list() 
					This method simply serializes the postings list created out of the documents in the corpus
					after they have been tokenized, cleansed off stop words and stemmed. The serialization
					format is a triplet(space delimited) of "term document-name frequency" and ordered by 
					terms. So incase a term "x" appears in 50 documents out of a 100 document corpus, the output 
					file will contain 50 rows, one for each of the documents with corresponding frequencies.

src/cluster.c :
	- This file has been added to demo the usage of the newly added functions. The file has been specifically added as a pre-
	  processing step for the clustering project. A corresponding Make file is also added in the build directory of the project.


bin/HierarchicalClustering.sh : 
	- This script file has been added to perform clustering based on FIHC algorithm. The above changes have been done specifically for this. The FIHC source and implementation can be found at : 



The clustering project makes use of the serialized index output of TBRS. The details regarding the clustering project are 
available in its respective repository.


Bugs/Enhancement Requests
-----------------------------			
Please do drop a mail for any bugs/enhancements to either/both of the developers.


-------------------------------------------------------------------------------------------------------------------------

*************************************************************************
* File : README.txt 							*
* Developers : Amar Lalwani 						*
* Raghav Bali 								*
* Date : Feb 20 2013 							*
* Author : Raghav Bali 							*
* Version : 0.9								*
*************************************************************************

This is a Boolean Retrieval System based on Porter's Stemmer.

The Project has the following folder structure :

-bin : contains all binary and object files generated by makefiles
-build : Contains make files for compiling the code. There are 5 different sample make files for compiling the examples
-include: Contains all the header files required for the project
-input : This folder should contain all the input/corpus text files for input to the project's examples
-src : Contains all the source files for the project including the examples
-output : Contains the output files generated by the tokenizer and stemmer

Dependencies : GNUPlot is the only dependency present in some of the examples to generate/plot graphs.
This project uses basic C libararies and does not require GNUplot or any other external library for its functioning.


The code is developed in a generic manner, however, there are certain specific standards which have been deliberately kept to make the code more understandable and extendable.
Standards :
-Corpus List : Programs take a corpus file's list as a (and only) command line input. This file list SHOULD be placed in /input directory for proper execution. Only the files mentioned in this list will be read by the sample programs for analysis and manipulaion. You may however choose to follow a different way for any further example you choose to develop.

-/input/stopwords.txt : The tokenizer works using stopwords.txt to remove the stop words from the corpus. The list of stopwords may wary and hence this facility is provided to change/add/delete the stopwords which are referred by the tokenizer. Keep in mind that the format of the stopwords.txt SHOULD still be maintained for proper working.

-Tokenizer Outputs : The tokenizer outputs the filtered words(removal of stop words) into a file named output_<filename> wherein the <filename> is the name of the input file tokenized by the tokenizer. The output file is always placed in the /output directory

-Stemmer Outputs : The tokenizer outputs the stemmed words into a file named stem_<tokenizer_output_filename> wherein the <tokenizer_output_filename> is the name of the file created by the tokenizer. The output file is always placed in the /output directory.


Execution :
---------------
The execution of the sample programs included in this project first require building/compiling the code. The following steps assume you have "make" utility (for Linux/Unix or any other similar utility for other operating systems).
1. Move into the build directory
2. Issue the command : make -f <makefile>
Where <makefile> is the name of one of the makefiles present in the build directory
3. On successful complilation, move to bin directory.
4. Issue the following command : ./<executable_filename> ../input/<inputfilelist>
where <inputfilelist> is the list of the corpus files required for analysis. You may place this file in any other directory as well.
5. Follow the onscreen instruction (if any).


NOTE : Some of the examples require GNU plot to be available on your system. Please install the same from http://people.duke.edu/~hpgavin/gnuplot.html

Examples Available :
---------------------
The build directory contains multiple makefiles, each for one of the following sample programs. You may apply your creativity to create some even better use cases. These examples are the basic ise cases of the project and serve as guides on how to use the library functions developed in the project.

-Makefile_example_compression_ratio : This builds and compiles the example which helps us analyse the compression ratio of between the words before and after stemming.

-Makefile_example_stemming : This builds and compiles the example which helps in understanding how Porter's algorithm works.

-Makefile_example_stopword_ratio : This builds and compiles the example which helps us analyse the %age of stopwords in a document.

-Makefile_example_tokenize : This builds and compiles the example which helps understand how the words are tokenized and stop words are filtered out.

-Makefile_keywordkxtraction : This builds and compiles the example which helps understand and work with Boolean queries to retrieve keywords across the corpus. This example uses all the library functions developed for this project.


Bugs
-----------------
Please drop a mail to either/both of the developers if you come across bugs/errors.


